{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHuZJkUaydq1"
      },
      "source": [
        "# Preparation\n",
        "Below are the steps from the original code to train and evaluate the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU1pTFWra2KH"
      },
      "source": [
        "## Official code for FriendNet and YOLOv7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5FXMDnpVyeFf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/fanyihua0309/FriendNet.git\n",
        "%cd FriendNet\n",
        "!git clone https://github.com/bubbliiiing/yolov7-tiny-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STijVwIPa6fw"
      },
      "source": [
        "## Datasets\n",
        "Download and unzip VOC-FOG dataset. Due to shortage of time, I cannot perform demo on Foggy-Driving dataset, however, the dataset can be found here https://www.kaggle.com/datasets/washingtongold/foggy-driving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Cc5Ky_Iyvra"
      },
      "outputs": [],
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/1bLUtwrKwzPwLI3yZBFZYw4BnINpxCfVp/view\n",
        "!unzip voc-fog(9578+2129).zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaHnZqkVzYBE"
      },
      "source": [
        "Move data to `FriendNet/data`, the folder structure is as below:\n",
        "\n",
        "```python\n",
        "┬─ data\n",
        "│   ├─ VOC-FOG\n",
        "│   │   ├─ train\n",
        "│   │   │   ├─ FogImages\n",
        "│   │   │   ├─ JPEGImages\n",
        "│   │   │   └─ Annotations\n",
        "│   │   └─ test\n",
        "│   │       ├─ FogImages\n",
        "│   │       ├─ JPEGImages\n",
        "│   │       └─ Annotations\n",
        "│   └─ Foggy-Driving\n",
        "│       └─ test\n",
        "│           ├─ FogImages\n",
        "│           ├─ JPEGImages\n",
        "│           └─ Annotations\n",
        "```\n",
        "\n",
        "Next, parse detection annotations and generate necessary text files for training, namely `train.txt` and `test.txt`. To train yolov7 model, remember to modify `convert_VOC_to_txt.py` to generate suitable annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5dP1_NFy6tR"
      },
      "outputs": [],
      "source": [
        "!python convert_VOC_to_txt.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVd-pZp0dXD3"
      },
      "source": [
        "# Train YOLOv7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD8w9S2UdkHW"
      },
      "source": [
        "Create a `train_detector.py` file to train yolov7 detector following the `train.py` from yolov7-tiny-pytorch repository \\\n",
        "Specify path for input labels, classes,... then train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4j5E0smehCji"
      },
      "outputs": [],
      "source": [
        "!python -m torch.distributed.launch --nproc_per_node=2 train_detector.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsXVWtIthE2P"
      },
      "source": [
        "Results can be found at `logs/`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maCK1KtNiLV3"
      },
      "source": [
        "# Train Dehaze Network\n",
        "Create a `train_dehaze.py` file. Steps in one epoch would be:\n",
        "*   get detection guidance from trained yolov7\n",
        "*   feed guidance and hazy image into network\n",
        "*   outputs are used to calculate restoration loss\n",
        "*   calculate final loss\n",
        "\n",
        "Some details that need modification\n",
        "\n",
        "\n",
        "*   `get_detection_guidance()` implementation\n",
        "*   Roll back `covert_VOC_to_txt.py` to get original format\n",
        "\n",
        "Execute the below script to train dehaze network. Results can be found at `logs_dehazed/`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiuMNe-X7mr2"
      },
      "outputs": [],
      "source": [
        "!python train_dehaze.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the below script to generate dehazed images. Change the `--dehaze_model_path` argument as you wish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python test_dehaze.py --input_dir=data/VOC-FOG/test/FogImages --output_dir=data/VOC-FOG/test/DehazedImages --dehaze_model_path=logs_dehazed/best_model.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the below script to generate detection results. Change the `--detech_model_path` argument as you wish\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python predict_detect.py --input_dir=data/VOC-FOG/test/DehazedImages --output_dir=data/VOC-FOG/test/DetectedImages --detect_model_path=logs/yolov7-tiny_clean_best_epoch_weights.pth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For fast evaluation, specify the path to hazy images, dehazed images, groundtruth images and labels folders. Then run the below script to get evaluation results including dehazed images, detection results, mAP, PSNR, SSIM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python quick_eval_script.py "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Some results: \n",
        "```python\n",
        "PSNR=29.1050, SSIM=0.9260\n",
        "\n",
        "37.55% = bicycle AP     ||      score_threhold=0.5 : F1=0.00 ; Recall=0.00% ; Precision=0.00%\n",
        "56.19% = bus AP         ||      score_threhold=0.5 : F1=0.13 ; Recall=7.19% ; Precision=66.67%\n",
        "56.99% = car AP         ||      score_threhold=0.5 : F1=0.36 ; Recall=22.69% ; Precision=88.29%\n",
        "40.67% = motorbike AP   ||      score_threhold=0.5 : F1=0.02 ; Recall=0.76% ; Precision=50.00%\n",
        "72.68% = person AP      ||      score_threhold=0.5 : F1=0.59 ; Recall=45.09% ; Precision=83.47%\n",
        "mAP = 52.82%\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the link to my source code:\n",
        "https://github.com/hongquant17/FriendNet \\\n",
        "Due to the privacy of the Residency Program, I will set the repository to private. Please contact me for access."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
